#title Archive for September, 2020

#p0
#date 20年9月19日 周六 23:57

## Object Storage 和 Shell 环境变量

找了几个 Object Storage 的方案，理想中的可以是去中心化的方案，然而找不到，找到的要么是 IPFS，要么是链圈的，太高大上了。退而求其次，分布式的的方案，就很多了，各大云商家的对象存储，其实蛮便宜的，还有基于 minio 的，基于 Redis Master-Slave 的方案，及其变种的也算一类，还有豆瓣的 [gobeandb](https://github.com/douban/gobeansdb)，以及 [bitraft](https://prologic.github.io/bitraft/) 和 [lf](https://github.com/zerotier/lf)，一个去中心化的 Key/Value Store.

因为有云服务器了，单独又开对象存储不大值得，因为需要存的东西不多，只是希望至少是分布式的，多个保全而已；minio 的方案，在分布式使用到时候，需要占用单独的磁盘，这个只好放弃了；Redis 及其变种 SSDB 之类的，底层 levelDB，或者占用内存多的放弃了，因为读写的频率很低，而且需要跟其他程序一起占用小排量的云服务器；gobeandb 犹犹豫豫很想用，但需要单独使用一个 goproxy 来分流感觉不大值得，接口是 memcached 的，手头也没有立即能用的解析器；bitraft 试用了一下，感觉最为接近，接口是 Redis 的，但是，无法基于不同数据中心做同步，我的两台云服务器位于不同的服务商它居然无法连接，就不说他默认 value 只有 64k 了；lf 一样没有趁手的接口，而且感觉不好配置。

bitraft 是最接近能用的，而且本地验证同步是很不错的，可惜了。

这里衬托了这么久，只是为了说自己最后写了一个，底层存储基于 [Tokyo Cabinet](https://dbmx.net/tokyocabinet/)，有现成的 Lua 绑定，网络服务接口用的是 [rpc_framework](https://github.com/lalawue/rpc_framework) 搭建的，同样基于 Redis 协议 [lua-resp](https://github.com/lalawue/lua-resp)，同步方案现在很挫的了，一个 master，slave 主动同步 master，启动的时候同步全部 key（也许后面可以优化），然后每隔 30 秒同步一次最新的 SET/DEL 操作；master 这边是每 15 秒区分一个操作 group，操作 group 里面记录所有的 SET/DEL 操作，有 slave 请求，就将 group 时间点及其之后的所有分组 group 操作同步过去；slave 每次都同步上次最新 group 时间点之后的操作数据。

如果 master 这边留了足够多时间跨度的操作 group，后续即便偶尔连不上也是可以保证接下来的数据的；不过目前确实没有考虑 slave 间隔读取不到 master 操作的问题。

为了安全，还加上了 AUTH 命令，简简单单，基本能用了，VALUE 的长度，跟 REDIS 一样是 512M，基本够用了。

Tokyo Cabinet 据说在 2kw 左右的数据量后，会读写缓慢，现在距离这个点还早得很，而且很可能都遇不上。更好的，当然是使用 bitcast 做底层存储，可惜目前也没有方案。

先这样吧，代码就不公开了，单机版在 rpc_framework apps 里做 demo 了。

--

方案找了好久，差不多一周，试用了 bitcast 半天，最后决定用自己的半成品，大概写了 2 天，郁闷的是后面半天时间，每次自己手动启动就正正常常的，但是使用服务推上去就跑不起来，slave 变成了 master。

后来发现，是接受推送，拉起服务的 service，没有使用到包含最新区分不同云服务商的 shell 变量，所以 fork 后拉起来的服务，自然就缺少这个 shell 变量了；手动启动正常，是因为 SSH 进去后每次都读取最新的 bash 配置。

囧啊。

#category Programming